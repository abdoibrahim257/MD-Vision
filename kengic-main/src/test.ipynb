{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def ngrams(x, n):\n",
    "    ngrams = []\n",
    "    for idx, ix in enumerate(x[0:len(x)-n+1]):\n",
    "        #print(idx, ix)\n",
    "        gram = x[idx:idx+n]\n",
    "        ngrams += [gram]\n",
    "        \n",
    "    return ngrams\n",
    "\n",
    "print(ngrams([\"large\", \"chunk\", \"of\", \"text\"], 3))\n",
    "ngrams1 = []\n",
    "#generate random tokens\n",
    "tokens = ['bear', 'market', 'is', 'coming', 'soon', 'but', 'bull', 'market', 'is', 'already', 'here']\n",
    "n1 = ngrams(['<t>'] + tokens + ['</t>'], 2)\n",
    "ngrams1 += n1\n",
    "print(ngrams1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def ngrams_from_dic_to_df(ngrams):\n",
    "    ngrams_dfs = {}\n",
    "    for ni in range(2, 6):\n",
    "        columns = [i for i in range(1,ni+1)]\n",
    "        print(columns)\n",
    "        ngrams_df = pd.DataFrame(ngrams[ni], columns=columns)\n",
    "        print(ngrams_df.head())\n",
    "        ngrams_df['count'] = 0\n",
    "        print(ngrams_df.head())\n",
    "        ngrams_df = ngrams_df.groupby(columns).count().sort_values(['count'], ascending=False).reset_index()\n",
    "        print(ngrams_df.head())\n",
    "        ngrams_df['probability'] = ngrams_df['count']/ngrams_df['count'].sum() #\n",
    "        print(ngrams_df)\n",
    "        ngrams_dfs[ni] = ngrams_df\n",
    "\n",
    "    return ngrams_dfs\n",
    "\n",
    "ngrams = {2: [['<t>', 'bear'], ['bear', 'market'], ['market', 'is'], ['is', 'coming'], ['coming', 'soon'], ['soon', 'but'], ['but', 'bull'], ['bull', 'market'], ['market', 'is'], ['is', 'already'], ['already', 'here'], ['here', '</t>']]}\n",
    "ngrams_from_dic_to_df(ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "offsets_list = []\n",
    "for split in np.array_split(np.arange(3), 2):\n",
    "    offsets_list += [[split[0], split[-1]+1]]\n",
    "    \n",
    "print(offsets_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = re.compile(r'\\d+(?=( cm))')\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Indiana Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read indiana dataset \n",
    "df = pd.read_csv('./indiana_reports.csv')\n",
    "\n",
    "#to capture\n",
    "measurement = re.compile(r'(\\d+(.\\d+)?)( )?((cm|mm)?( )?(x) (\\d+(.\\d+)?) )?(cm|mm)')\n",
    "ratio = re.compile(r'(\\d+(.\\d+)\\/)')\n",
    "rankNumbers = re.compile(r'[0-9](st|nd|rd|th)', re.I)\n",
    "words = re.compile(r'(day|film|recommend|prior|comparison|compare|image|T6|T8|T11|T12)', re.I)\n",
    "intact = re.compile(r'((?<= )( )?(is|are) intact)|((?<=  )(is|are) unremarkable)')\n",
    "#create a new dataframe df2\n",
    "df2 = pd.DataFrame()\n",
    "# df2['uid'] = df['uid']\n",
    "\n",
    "df['findings'] = df['findings'].str.replace(r'XXXX', '',regex = True)\n",
    "df['impression'] = df['impression'].str.replace(r'(XXXX\\.|XXXX)', '',regex = True)\n",
    "\n",
    "#removing any 2.0 cm or 2.0 x 2.0 cm or 2.0 cm or 2.0mm or 2.0 x 2.0mm or 2.0mm x 2.0mm etc.\n",
    "# df['findings'] = df['findings'].str.replace(r'(\\d+(.\\d+)?)( )?((cm|mm)?( )?(x) (\\d+(.\\d+)?) )?(cm|mm)', '',regex=True)\n",
    "# df['impression'] = df['impression'].str.replace(r'(\\d+(.\\d+)?)( )?((cm|mm)?( )?(x) (\\d+(.\\d+)?) )?(cm|mm)', '',regex=True)\n",
    "\n",
    "#remove any list numbu2. 3. and so on\n",
    "df['findings'] = df['findings'].str.replace(r'([0-9](\\.))|(^[0-9](\\.))', '',regex=True)\n",
    "df['impression'] = df['impression'].str.replace(r'([0-9](\\.))|(^[0-9](\\.))', '',regex=True) \n",
    "\n",
    "#remove comas\n",
    "df['findings'] = df['findings'].str.replace(r',|-', '',regex=True)\n",
    "df['impression'] = df['impression'].str.replace(r',|-', '',regex=True)\n",
    "\n",
    "#split each to plst of sentences \n",
    "df['findings'] = df['findings'].map(lambda x: str(x).split('.'))\n",
    "df['impression'] = df['impression'].map(lambda x: str(x).split('.'))\n",
    "\n",
    "\n",
    "df['findings'] = df['findings'].apply(lambda x: [sentence for sentence in x if not (intact.search(sentence) or words.search(sentence) or rankNumbers.search(sentence) or measurement.search(sentence) or ratio.search(sentence))])\n",
    "df['impression'] = df['impression'].apply(lambda x: [sentence for sentence in x if not (intact.search(sentence) or words.search(sentence) or rankNumbers.search(sentence) or measurement.search(sentence) or ratio.search(sentence))])\n",
    "\n",
    "#loop on the each senctence in the list of sentences and remove any remaining numbers from the sentence \n",
    "df['findings'] = df['findings'].apply(lambda x: [re.sub(r'\\d+', '', sentence) for sentence in x])\n",
    "df['impression'] = df['impression'].apply(lambda x: [re.sub(r'\\d+', '', sentence) for sentence in x])\n",
    "\n",
    "#remove any empty sentences\n",
    "df['findings'] = df['findings'].apply(lambda x: [sentence for sentence in x if sentence.strip()])\n",
    "df['impression'] = df['impression'].apply(lambda x: [sentence for sentence in x if sentence.strip()])\n",
    "\n",
    "df2['imgID']= df['uid']\n",
    "\n",
    "df2['captions'] = df['findings'] + df['impression']\n",
    "\n",
    "df2['captions'] = df2['captions'].apply(lambda x: [sentence.split() for sentence in x if sentence != 'nan'])\n",
    "df2['captions'] = df2['captions'].apply(lambda x: [sentence for sentence in x if len(sentence) >2])\n",
    "# remove row with empty list\n",
    "df2 = df2[df2['captions'].map(len) > 0]\n",
    "\n",
    "# df2 = df2[df2['captions'].map(len) > 2]\n",
    "\n",
    "df2.to_csv('indiana_reports_cleaned2.csv', index=False)\n",
    "\n",
    "df3 = pd.DataFrame()\n",
    "df3 = df2.explode(\"captions\")\n",
    "df3.explode(\"captions\")\n",
    "#save df2 in csv \n",
    "# split sentence and remove any row that has words that are <= 2\n",
    "df3 = df3['captions'].map(lambda x: str(x).split())\n",
    "# remove any row of size <= 2 \n",
    "df3 = df3[df3.map(len) > 2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [[The cardiac silhouette and mediastinum size ...\n",
      "1    [[Borderline cardiomegaly], [ Midline sternoto...\n",
      "2    [[No displaced rib fractures pneumothorax or p...\n",
      "3    [[There are diffuse bilateral interstitial and...\n",
      "4    [[The cardiomediastinal silhouette and pulmona...\n",
      "Name: captions, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(df2.head()['captions'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3851, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.DataFrame(df3)\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'iterrows'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23976\\621176899.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-----------------'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'captions'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\amr23\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5985\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5986\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5987\u001b[0m         ):\n\u001b[0;32m   5988\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5989\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'iterrows'"
     ]
    }
   ],
   "source": [
    "for index, row in df3.iterrows():\n",
    "    print(row)\n",
    "    print('-----------------')\n",
    "    print(row['captions'])\n",
    "    print('-----------------')\n",
    "    if index > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['There', 'are', 'diffuse', 'bilateral', 'interstitial', 'and', 'alveolar', 'opacities', 'consistent', 'with', 'chronic', 'obstructive', 'lung', 'disease', 'and', 'bullous', 'emphysema'], ['There', 'are', 'irregular', 'opacities', 'in', 'the', 'left', 'lung', 'apex', 'that', 'could', 'represent', 'a', 'cavitary', 'lesion', 'in', 'the', 'left', 'lung', 'apex'], ['There', 'are', 'streaky', 'opacities', 'in', 'the', 'right', 'upper', 'lobe', 'scarring'], ['The', 'cardiomediastinal', 'silhouette', 'is', 'normal', 'in', 'size', 'and', 'contour'], ['There', 'is', 'no', 'pneumothorax', 'or', 'large', 'pleural', 'effusion'], ['Bullous', 'emphysema', 'and', 'interstitial', 'fibrosis'], ['Probably', 'scarring', 'in', 'the', 'left', 'apex', 'although', 'difficult', 'to', 'exclude', 'a', 'cavitary', 'lesion']]\n"
     ]
    }
   ],
   "source": [
    "for index, row in df2.iterrows():\n",
    "    if index == 3:\n",
    "        print(row['captions'])\n",
    "        # print(row['impression'])\n",
    "        break\n",
    "    # print(row['captions'])\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.explode(\"captions\")\n",
    "df3.explode(\"captions\")\n",
    "#save df2 in csv \n",
    "# split sentence and remove any row that has words that are <= 2\n",
    "df3 = df3['captions'].map(lambda x: str(x).split())\n",
    "# remove any row of size <= 2 \n",
    "df3 = df3[df3.map(len) > 2]\n",
    "\n",
    "df3.to_csv('indiana_reports_cleaned.csv', index=False)\n",
    "# print(df3.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newList = df3.values.tolist()\n",
    "# Convert each inner list to a tuple and add them to a set\n",
    "unique_reference = set(tuple(x) for x in newList)\n",
    "\n",
    "# Convert each tuple in the set back to a list\n",
    "unique_reference = [list(x) for x in unique_reference]\n",
    "\n",
    "print(unique_reference[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t = \"SDKMASKDM SDMAKODAOMDKOMASDASD\"\n",
    "print(t.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# read\n",
    "df = pd.read_parquet('D:/GAM3A/5-Senior02/GP/KENGIC/MIMIC-medical-report/data/train-00000-of-00001-0dc3c7ebb0311aec.parquet')\n",
    "formatted_df = pd.DataFrame()\n",
    "#split the text given in to sentences\n",
    "#remove the following from findings and impression\n",
    "# any ___\n",
    "formatted_df['FINDINGS'] = df['FINDINGS'].str.replace(r'___', '', regex = True)\n",
    "formatted_df['IMPRESSION'] = df['IMPRESSION'].str.replace(r'___', '', regex = True)\n",
    "\n",
    "# any Dr.\n",
    "formatted_df['FINDINGS'] = formatted_df['FINDINGS'].str.replace(r'Dr.', '', regex = True)\n",
    "formatted_df['IMPRESSION'] = formatted_df['IMPRESSION'].str.replace(r'Dr.', '', regex = True)\n",
    "\n",
    "# any time formats ex: at 12:00 / at floating numbers\n",
    "formatted_df['FINDINGS'] = formatted_df['FINDINGS'].str.replace(r'(at \\d{1,2}:\\d{1,2})|(\\d{1,2}:\\d{1,2})', '', regex = True)\n",
    "formatted_df['IMPRESSION'] = formatted_df['IMPRESSION'].str.replace(r'(at \\d{1,2}:\\d{1,2})|(\\d{1,2}:\\d{1,2})', '', regex = True)\n",
    "\n",
    "# any p.m/a.m/am/pm\n",
    "formatted_df['FINDINGS'] = formatted_df['FINDINGS'].str.replace(r'( am )|( pm )|( p\\.m)|( a\\.m)', '', regex = True)\n",
    "formatted_df['IMPRESSION'] = formatted_df['IMPRESSION'].str.replace(r'( am )|( pm )|( p\\.m)|( a\\.m)', '', regex = True)\n",
    "\n",
    "# remove floating numbers followed by measurements ex: 12.5\n",
    "formatted_df['FINDINGS'] = formatted_df['FINDINGS'].str.replace(r'\\d+\\.\\d+', '', regex = True)\n",
    "formatted_df['FINDINGS'] = formatted_df['FINDINGS'].str.replace(r'\\d+\\.', '', regex = True)\n",
    "formatted_df['IMPRESSION'] = formatted_df['IMPRESSION'].str.replace(r'\\d+\\.\\d+', '', regex = True)\n",
    "formatted_df['IMPRESSION'] = formatted_df['IMPRESSION'].str.replace(r'\\d+\\.', '', regex = True)\n",
    "\n",
    "#remove any cm mm inch\n",
    "formatted_df['FINDINGS'] = formatted_df['FINDINGS'].str.replace(r'( cm)|( mm)', '', regex = True)\n",
    "formatted_df['IMPRESSION'] = formatted_df['IMPRESSION'].str.replace(r'( cm)|( mm)', '', regex = True)\n",
    "\n",
    "# remove any 1.,2.,3.,etc.\n",
    "#done in the above step\n",
    "\n",
    "# remove , =\n",
    "formatted_df['FINDINGS'] = formatted_df['FINDINGS'].str.replace(r',|=', '', regex = True)\n",
    "formatted_df['IMPRESSION'] = formatted_df['IMPRESSION'].str.replace(r',|=', '', regex = True)\n",
    "\n",
    "#remove any numbers\n",
    "formatted_df['FINDINGS'] = formatted_df['FINDINGS'].str.replace(r'\\d+', '', regex = True)\n",
    "formatted_df['IMPRESSION'] = formatted_df['IMPRESSION'].str.replace(r'\\d+', '', regex = True)\n",
    "\n",
    "#remove any \\n\n",
    "formatted_df['FINDINGS'] = formatted_df['FINDINGS'].str.replace(r'\\n', '', regex = True)\n",
    "formatted_df['IMPRESSION'] = formatted_df['IMPRESSION'].str.replace(r'\\n', '', regex = True)\n",
    "\n",
    "#split each paragraph on .\n",
    "formatted_df['FINDINGS'] = formatted_df['FINDINGS'].map(lambda x: str(x).split('.'))\n",
    "formatted_df['IMPRESSION'] = formatted_df['IMPRESSION'].map(lambda x: str(x).split('.'))\n",
    "\n",
    "#remove empty strings\n",
    "formatted_df['FINDINGS'] = formatted_df['FINDINGS'].map(lambda x: [i.split() for i in x if i != ''])\n",
    "formatted_df['IMPRESSION'] = formatted_df['IMPRESSION'].map(lambda x: [i.split() for i in x if i != ''])\n",
    "\n",
    "#check for since, through, by, on,\n",
    "#make every token a lower case \n",
    "formatted_df['FINDINGS'] = formatted_df['FINDINGS'].apply(lambda x: [[word.lower() for word in sentence] for sentence in x])\n",
    "formatted_df['IMPRESSION'] = formatted_df['IMPRESSION'].apply(lambda x: [[word.lower() for word in sentence] for sentence in x])\n",
    "\n",
    "\n",
    "# #remove at ; however, new, from the sentence \n",
    "toRemove = ['at', 'however', 'new', 'from',';']\n",
    "formatted_df['FINDINGS'] = formatted_df['FINDINGS'].apply(lambda x: [[word for word in sentence if word not in toRemove] for sentence in x])\n",
    "formatted_df['IMPRESSION'] = formatted_df['IMPRESSION'].apply(lambda x: [[word for word in sentence if word not in toRemove] for sentence in x])\n",
    "\n",
    "\n",
    "#remove sentence with through, since, submitted, unchanged, compared, comparison, previous, prior,increase, decrease,increased, decreased,\n",
    "#findings, film, PICC, yesterday, today, SVC, tube,  \n",
    "toRemoveSentence = ['through', 'since', 'submitted', 'unchanged', 'compared', 'comparison', 'previous', 'prior', 'increase', 'decrease', 'increased', 'decreased', 'findings', 'film', 'picc', 'yesterday', 'today', 'svc', 'tubes']\n",
    "formatted_df['FINDINGS'] = formatted_df['FINDINGS'].apply(lambda x: [sentence for sentence in x if not any(word in sentence for word in toRemoveSentence)])\n",
    "formatted_df['IMPRESSION'] = formatted_df['IMPRESSION'].apply(lambda x: [sentence for sentence in x if not any(word in sentence for word in toRemoveSentence)])\n",
    "\n",
    "finalDf = pd.DataFrame()\n",
    "finalDf['captions'] = formatted_df['FINDINGS'] + formatted_df['IMPRESSION']\n",
    "\n",
    "# remove ['as','above'],['status','quo']\n",
    "toRemoveSentence = ['above', 'quo']\n",
    "finalDf['captions'] = finalDf['captions'].apply(lambda x: [sentence for sentence in x if (not any(word in sentence for word in toRemoveSentence) and len(sentence) > 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split lists to row\n",
    "new = finalDf.explode('captions')\n",
    "newList = new['captions'].tolist()\n",
    "print(len(newList))\n",
    "# Convert each inner list to a tuple and add them to a set\n",
    "# print(type(newList))\n",
    "unique_ref = set()\n",
    "for x in newList:\n",
    "    if isinstance(x, list):\n",
    "        t = tuple(x)\n",
    "        unique_ref.add(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert from set of tuple to list of list\n",
    "unique_ref = [list(x) for x in unique_ref]\n",
    "print(len(unique_ref))\n",
    "print(unique_ref[7440])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in new.iterrows():\n",
    "    if index == 224:\n",
    "        print(\"captions: \",row['captions'])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(finalDf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in finalDf.iterrows():\n",
    "    if index == 223:\n",
    "        print(\"captions: \",row['captions'])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for index, row in formatted_df.iterrows():\n",
    "    if r'am' in (row['FINDINGS']) :\n",
    "        count+=1\n",
    "        print('index:', index)\n",
    "        print(\"FINDINGS: \",row['FINDINGS'])\n",
    "        print('-----------------------------------')\n",
    "        if r'am' in (row['IMPRESSION']):\n",
    "            count+=1\n",
    "            print(\"IMPRESSION: \",row['IMPRESSION'])\n",
    "            print('===================================')\n",
    "        \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for index, row in formatted_df.iterrows():\n",
    "    if r'since  ' in (row['FINDINGS']) :\n",
    "        count+=1\n",
    "        print('index:', index)\n",
    "        print(\"FINDINGS: \",row['FINDINGS'])\n",
    "        print('-----------------------------------')\n",
    "        if r'since  ' in (row['IMPRESSION']):\n",
    "            count+=1\n",
    "            print(\"IMPRESSION: \",row['IMPRESSION'])\n",
    "            print('===================================')\n",
    "        \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for index, row in formatted_df.iterrows():\n",
    "    if r'through  ' in (row['FINDINGS']) :\n",
    "        count+=1\n",
    "        print('index:', index)\n",
    "        print(\"FINDINGS: \",row['FINDINGS'])\n",
    "        print('-----------------------------------')\n",
    "        if r'through  ' in (row['IMPRESSION']):\n",
    "            count+=1\n",
    "            print(\"IMPRESSION: \",row['IMPRESSION'])\n",
    "            print('===================================')\n",
    "        \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for index, row in formatted_df.iterrows():\n",
    "    if r'at  ' in (row['FINDINGS']) :\n",
    "        count+=1\n",
    "        print('index:', index)\n",
    "        print(\"FINDINGS: \",row['FINDINGS'])\n",
    "        print('-----------------------------------')\n",
    "        if r'at  ' in (row['IMPRESSION']):\n",
    "            count+=1\n",
    "            print(\"IMPRESSION: \",row['IMPRESSION'])\n",
    "            print('===================================')\n",
    "        \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for index, row in formatted_df.iterrows():\n",
    "    if r'PICC' in (row['FINDINGS']) :\n",
    "        count+=1\n",
    "        print('index:', index)\n",
    "        print(\"FINDINGS: \",row['FINDINGS'])\n",
    "        print('-----------------------------------')\n",
    "        if r'PICC' in (row['IMPRESSION']):\n",
    "            count+=1\n",
    "            print(\"IMPRESSION: \",row['IMPRESSION'])\n",
    "            print('===================================')\n",
    "        \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for index, row in formatted_df.iterrows():\n",
    "    if r'from  ' in (row['FINDINGS']) :\n",
    "        count+=1\n",
    "        print('index:', index)\n",
    "        print(\"FINDINGS: \",row['FINDINGS'])\n",
    "        print('-----------------------------------')\n",
    "        if r'from  ' in (row['IMPRESSION']):\n",
    "            count+=1\n",
    "            print(\"IMPRESSION: \",row['IMPRESSION'])\n",
    "            print('===================================')\n",
    "        \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print sentences that has \"by\" in it from the dataframe formatted_df\n",
    "count = 0\n",
    "for index, row in formatted_df.iterrows():\n",
    "    if r'by  ' in (row['FINDINGS']) :\n",
    "        count+=1\n",
    "        print('index:', index)\n",
    "        print(\"FINDINGS: \",row['FINDINGS'])\n",
    "        print('-----------------------------------')\n",
    "        if r'by  ' in (row['IMPRESSION']):\n",
    "            count+=1\n",
    "            print(\"IMPRESSION: \",row['IMPRESSION'])\n",
    "            print('===================================')\n",
    "        \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in formatted_df.iterrows():\n",
    "    if index == 9:\n",
    "        print(\"FININDINS:\", row['FINDINGS'])\n",
    "        print(\"IMPRESSION:\", row['IMPRESSION'])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#bleu score for a single sentence\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtranslate\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbleu_score\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sentence_bleu\n\u001b[0;32m      4\u001b[0m reference \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthis\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m], [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthis\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m      5\u001b[0m candidate \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthis\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mare\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Abdoi\\anaconda3\\Lib\\site-packages\\nltk\\__init__.py:135\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcollocations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecorators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m decorator, memoize\n\u001b[1;32m--> 135\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeatstruct\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgrammar\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprobability\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Abdoi\\anaconda3\\Lib\\site-packages\\nltk\\featstruct.py:97\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m total_ordering\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternals\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m raise_unorderable_types, read_str\n\u001b[1;32m---> 97\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msem\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     98\u001b[0m     Expression,\n\u001b[0;32m     99\u001b[0m     LogicalExpressionException,\n\u001b[0;32m    100\u001b[0m     LogicParser,\n\u001b[0;32m    101\u001b[0m     SubstituteBindingsI,\n\u001b[0;32m    102\u001b[0m     Variable,\n\u001b[0;32m    103\u001b[0m )\n\u001b[0;32m    105\u001b[0m \u001b[38;5;66;03m######################################################################\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# Feature Structure\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m######################################################################\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;129m@total_ordering\u001b[39m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mFeatStruct\u001b[39;00m(SubstituteBindingsI):\n",
      "File \u001b[1;32mc:\\Users\\Abdoi\\anaconda3\\Lib\\site-packages\\nltk\\sem\\__init__.py:56\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msem\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdrt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DRS, DrtExpression\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msem\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     47\u001b[0m     Assignment,\n\u001b[0;32m     48\u001b[0m     Model,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     54\u001b[0m     set2rel,\n\u001b[0;32m     55\u001b[0m )\n\u001b[1;32m---> 56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msem\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlfg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FStructure\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msem\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     58\u001b[0m     ApplicationExpression,\n\u001b[0;32m     59\u001b[0m     Expression,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     65\u001b[0m     read_logic,\n\u001b[0;32m     66\u001b[0m )\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msem\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrelextract\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clause, extract_rels, rtuple\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:936\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1032\u001b[0m, in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1131\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#bleu score for a single sentence\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "reference = [['this', 'is', 'a', 'test'], ['this', 'is', 'a', 'test']]\n",
    "candidate = ['this', 'are', 'test']\n",
    "\n",
    "score = sentence_bleu(reference, candidate)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

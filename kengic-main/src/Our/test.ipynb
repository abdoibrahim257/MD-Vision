{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def ngrams(x, n):\n",
    "    ngrams = []\n",
    "    for idx, ix in enumerate(x[0:len(x)-n+1]):\n",
    "        #print(idx, ix)\n",
    "        gram = x[idx:idx+n]\n",
    "        ngrams += [gram]\n",
    "        \n",
    "    return ngrams\n",
    "\n",
    "print(ngrams([\"large\", \"chunk\", \"of\", \"text\"], 3))\n",
    "ngrams1 = []\n",
    "#generate random tokens\n",
    "tokens = ['bear', 'market', 'is', 'coming', 'soon', 'but', 'bull', 'market', 'is', 'already', 'here']\n",
    "n1 = ngrams(['<t>'] + tokens + ['</t>'], 2)\n",
    "ngrams1 += n1\n",
    "print(ngrams1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def ngrams_from_dic_to_df(ngrams):\n",
    "    ngrams_dfs = {}\n",
    "    for ni in range(2, 6):\n",
    "        columns = [i for i in range(1,ni+1)]\n",
    "        print(columns)\n",
    "        ngrams_df = pd.DataFrame(ngrams[ni], columns=columns)\n",
    "        print(ngrams_df.head())\n",
    "        ngrams_df['count'] = 0\n",
    "        print(ngrams_df.head())\n",
    "        ngrams_df = ngrams_df.groupby(columns).count().sort_values(['count'], ascending=False).reset_index()\n",
    "        print(ngrams_df.head())\n",
    "        ngrams_df['probability'] = ngrams_df['count']/ngrams_df['count'].sum() #\n",
    "        print(ngrams_df)\n",
    "        ngrams_dfs[ni] = ngrams_df\n",
    "\n",
    "    return ngrams_dfs\n",
    "\n",
    "ngrams = {2: [['<t>', 'bear'], ['bear', 'market'], ['market', 'is'], ['is', 'coming'], ['coming', 'soon'], ['soon', 'but'], ['but', 'bull'], ['bull', 'market'], ['market', 'is'], ['is', 'already'], ['already', 'here'], ['here', '</t>']]}\n",
    "ngrams_from_dic_to_df(ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "offsets_list = []\n",
    "for split in np.array_split(np.arange(3), 2):\n",
    "    offsets_list += [[split[0], split[-1]+1]]\n",
    "    \n",
    "print(offsets_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = re.compile(r'\\d+(?=( cm))')\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Indiana Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read indiana dataset \n",
    "df = pd.read_csv('./indiana_reports.csv')\n",
    "\n",
    "#to capture\n",
    "measurement = re.compile(r'(\\d+(.\\d+)?)( )?((cm|mm)?( )?(x) (\\d+(.\\d+)?) )?(cm|mm)')\n",
    "ratio = re.compile(r'(\\d+(.\\d+)\\/)')\n",
    "rankNumbers = re.compile(r'[0-9](st|nd|rd|th)', re.I)\n",
    "words = re.compile(r'(day|film|recommend|prior|comparison|compare|image|T6|T8|T11|T12)', re.I)\n",
    "intact = re.compile(r'((?<= )( )?(is|are) intact)|((?<=  )(is|are) unremarkable)')\n",
    "#create a new dataframe df2\n",
    "df2 = pd.DataFrame()\n",
    "# df2['uid'] = df['uid']\n",
    "\n",
    "df['findings'] = df['findings'].str.replace(r'XXXX', '',regex = True)\n",
    "df['impression'] = df['impression'].str.replace(r'(XXXX\\.|XXXX)', '',regex = True)\n",
    "\n",
    "#removing any 2.0 cm or 2.0 x 2.0 cm or 2.0 cm or 2.0mm or 2.0 x 2.0mm or 2.0mm x 2.0mm etc.\n",
    "# df['findings'] = df['findings'].str.replace(r'(\\d+(.\\d+)?)( )?((cm|mm)?( )?(x) (\\d+(.\\d+)?) )?(cm|mm)', '',regex=True)\n",
    "# df['impression'] = df['impression'].str.replace(r'(\\d+(.\\d+)?)( )?((cm|mm)?( )?(x) (\\d+(.\\d+)?) )?(cm|mm)', '',regex=True)\n",
    "\n",
    "#remove any list numbu2. 3. and so on\n",
    "df['findings'] = df['findings'].str.replace(r'([0-9](\\.))|(^[0-9](\\.))', '',regex=True)\n",
    "df['impression'] = df['impression'].str.replace(r'([0-9](\\.))|(^[0-9](\\.))', '',regex=True) \n",
    "\n",
    "#remove comas\n",
    "df['findings'] = df['findings'].str.replace(r',|-', '',regex=True)\n",
    "df['impression'] = df['impression'].str.replace(r',|-', '',regex=True)\n",
    "\n",
    "#split each to plst of sentences \n",
    "df['findings'] = df['findings'].map(lambda x: str(x).split('.'))\n",
    "df['impression'] = df['impression'].map(lambda x: str(x).split('.'))\n",
    "\n",
    "\n",
    "df['findings'] = df['findings'].apply(lambda x: [sentence for sentence in x if not (intact.search(sentence) or words.search(sentence) or rankNumbers.search(sentence) or measurement.search(sentence) or ratio.search(sentence))])\n",
    "df['impression'] = df['impression'].apply(lambda x: [sentence for sentence in x if not (intact.search(sentence) or words.search(sentence) or rankNumbers.search(sentence) or measurement.search(sentence) or ratio.search(sentence))])\n",
    "\n",
    "#loop on the each senctence in the list of sentences and remove any remaining numbers from the sentence \n",
    "df['findings'] = df['findings'].apply(lambda x: [re.sub(r'\\d+', '', sentence) for sentence in x])\n",
    "df['impression'] = df['impression'].apply(lambda x: [re.sub(r'\\d+', '', sentence) for sentence in x])\n",
    "\n",
    "#remove any empty sentences\n",
    "df['findings'] = df['findings'].apply(lambda x: [sentence for sentence in x if sentence.strip()])\n",
    "df['impression'] = df['impression'].apply(lambda x: [sentence for sentence in x if sentence.strip()])\n",
    "\n",
    "df2['imgID']= df['uid']\n",
    "\n",
    "df2['captions'] = df['findings'] + df['impression']\n",
    "\n",
    "df2['captions'] = df2['captions'].apply(lambda x: [sentence.split() for sentence in x if sentence != 'nan'])\n",
    "df2['captions'] = df2['captions'].apply(lambda x: [sentence for sentence in x if len(sentence) >2])\n",
    "# remove row with empty list\n",
    "df2 = df2[df2['captions'].map(len) > 0]\n",
    "\n",
    "# df2 = df2[df2['captions'].map(len) > 2]\n",
    "\n",
    "df2.to_csv('indiana_reports_cleaned2.csv', index=False)\n",
    "\n",
    "df3 = pd.DataFrame()\n",
    "df3 = df2.explode(\"captions\")\n",
    "df3.explode(\"captions\")\n",
    "#save df2 in csv \n",
    "# split sentence and remove any row that has words that are <= 2\n",
    "df3 = df3['captions'].map(lambda x: str(x).split())\n",
    "# remove any row of size <= 2 \n",
    "df3 = df3[df3.map(len) > 2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(df2.head()['captions'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(df3)\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df3.iterrows():\n",
    "    print(row)\n",
    "    print('-----------------')\n",
    "    print(row['captions'])\n",
    "    print('-----------------')\n",
    "    if index > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df2.iterrows():\n",
    "    if index == 3:\n",
    "        print(row['captions'])\n",
    "        # print(row['impression'])\n",
    "        break\n",
    "    # print(row['captions'])\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.explode(\"captions\")\n",
    "df3.explode(\"captions\")\n",
    "#save df2 in csv \n",
    "# split sentence and remove any row that has words that are <= 2\n",
    "df3 = df3['captions'].map(lambda x: str(x).split())\n",
    "# remove any row of size <= 2 \n",
    "df3 = df3[df3.map(len) > 2]\n",
    "\n",
    "df3.to_csv('indiana_reports_cleaned.csv', index=False)\n",
    "# print(df3.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newList = df3.values.tolist()\n",
    "# Convert each inner list to a tuple and add them to a set\n",
    "unique_reference = set(tuple(x) for x in newList)\n",
    "\n",
    "# Convert each tuple in the set back to a list\n",
    "unique_reference = [list(x) for x in unique_reference]\n",
    "\n",
    "print(unique_reference[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t = \"SDKMASKDM SDMAKODAOMDKOMASDASD\"\n",
    "print(t.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# read\n",
    "df = pd.read_parquet('D:/GAM3A/5-Senior02/GP/KENGIC/MIMIC-medical-report/data/train-00000-of-00001-0dc3c7ebb0311aec.parquet')\n",
    "formatted_df = pd.DataFrame()\n",
    "#split the text given in to sentences\n",
    "#remove the following from findings and impression\n",
    "# any ___\n",
    "formatted_df['FINDINGS'] = df['FINDINGS'].str.replace(r'___', '', regex = True)\n",
    "formatted_df['IMPRESSION'] = df['IMPRESSION'].str.replace(r'___', '', regex = True)\n",
    "\n",
    "# any Dr.\n",
    "formatted_df['FINDINGS'] = formatted_df['FINDINGS'].str.replace(r'Dr.', '', regex = True)\n",
    "formatted_df['IMPRESSION'] = formatted_df['IMPRESSION'].str.replace(r'Dr.', '', regex = True)\n",
    "\n",
    "# any time formats ex: at 12:00 / at floating numbers\n",
    "formatted_df['FINDINGS'] = formatted_df['FINDINGS'].str.replace(r'(at \\d{1,2}:\\d{1,2})|(\\d{1,2}:\\d{1,2})', '', regex = True)\n",
    "formatted_df['IMPRESSION'] = formatted_df['IMPRESSION'].str.replace(r'(at \\d{1,2}:\\d{1,2})|(\\d{1,2}:\\d{1,2})', '', regex = True)\n",
    "\n",
    "# any p.m/a.m/am/pm\n",
    "formatted_df['FINDINGS'] = formatted_df['FINDINGS'].str.replace(r'( am )|( pm )|( p\\.m)|( a\\.m)', '', regex = True)\n",
    "formatted_df['IMPRESSION'] = formatted_df['IMPRESSION'].str.replace(r'( am )|( pm )|( p\\.m)|( a\\.m)', '', regex = True)\n",
    "\n",
    "# remove floating numbers followed by measurements ex: 12.5\n",
    "formatted_df['FINDINGS'] = formatted_df['FINDINGS'].str.replace(r'\\d+\\.\\d+', '', regex = True)\n",
    "formatted_df['FINDINGS'] = formatted_df['FINDINGS'].str.replace(r'\\d+\\.', '', regex = True)\n",
    "formatted_df['IMPRESSION'] = formatted_df['IMPRESSION'].str.replace(r'\\d+\\.\\d+', '', regex = True)\n",
    "formatted_df['IMPRESSION'] = formatted_df['IMPRESSION'].str.replace(r'\\d+\\.', '', regex = True)\n",
    "\n",
    "#remove any cm mm inch\n",
    "formatted_df['FINDINGS'] = formatted_df['FINDINGS'].str.replace(r'( cm)|( mm)', '', regex = True)\n",
    "formatted_df['IMPRESSION'] = formatted_df['IMPRESSION'].str.replace(r'( cm)|( mm)', '', regex = True)\n",
    "\n",
    "# remove any 1.,2.,3.,etc.\n",
    "#done in the above step\n",
    "\n",
    "# remove , =\n",
    "formatted_df['FINDINGS'] = formatted_df['FINDINGS'].str.replace(r',|=', '', regex = True)\n",
    "formatted_df['IMPRESSION'] = formatted_df['IMPRESSION'].str.replace(r',|=', '', regex = True)\n",
    "\n",
    "#remove any numbers\n",
    "formatted_df['FINDINGS'] = formatted_df['FINDINGS'].str.replace(r'\\d+', '', regex = True)\n",
    "formatted_df['IMPRESSION'] = formatted_df['IMPRESSION'].str.replace(r'\\d+', '', regex = True)\n",
    "\n",
    "#remove any \\n\n",
    "formatted_df['FINDINGS'] = formatted_df['FINDINGS'].str.replace(r'\\n', '', regex = True)\n",
    "formatted_df['IMPRESSION'] = formatted_df['IMPRESSION'].str.replace(r'\\n', '', regex = True)\n",
    "\n",
    "#split each paragraph on .\n",
    "formatted_df['FINDINGS'] = formatted_df['FINDINGS'].map(lambda x: str(x).split('.'))\n",
    "formatted_df['IMPRESSION'] = formatted_df['IMPRESSION'].map(lambda x: str(x).split('.'))\n",
    "\n",
    "#remove empty strings\n",
    "formatted_df['FINDINGS'] = formatted_df['FINDINGS'].map(lambda x: [i.split() for i in x if i != ''])\n",
    "formatted_df['IMPRESSION'] = formatted_df['IMPRESSION'].map(lambda x: [i.split() for i in x if i != ''])\n",
    "\n",
    "#check for since, through, by, on,\n",
    "#make every token a lower case \n",
    "formatted_df['FINDINGS'] = formatted_df['FINDINGS'].apply(lambda x: [[word.lower() for word in sentence] for sentence in x])\n",
    "formatted_df['IMPRESSION'] = formatted_df['IMPRESSION'].apply(lambda x: [[word.lower() for word in sentence] for sentence in x])\n",
    "\n",
    "\n",
    "# #remove at ; however, new, from the sentence \n",
    "toRemove = ['at', 'however', 'new', 'from',';']\n",
    "formatted_df['FINDINGS'] = formatted_df['FINDINGS'].apply(lambda x: [[word for word in sentence if word not in toRemove] for sentence in x])\n",
    "formatted_df['IMPRESSION'] = formatted_df['IMPRESSION'].apply(lambda x: [[word for word in sentence if word not in toRemove] for sentence in x])\n",
    "\n",
    "\n",
    "#remove sentence with through, since, submitted, unchanged, compared, comparison, previous, prior,increase, decrease,increased, decreased,\n",
    "#findings, film, PICC, yesterday, today, SVC, tube,  \n",
    "toRemoveSentence = ['through', 'since', 'submitted', 'unchanged', 'compared', 'comparison', 'previous', 'prior', 'increase', 'decrease', 'increased', 'decreased', 'findings', 'film', 'picc', 'yesterday', 'today', 'svc', 'tubes']\n",
    "formatted_df['FINDINGS'] = formatted_df['FINDINGS'].apply(lambda x: [sentence for sentence in x if not any(word in sentence for word in toRemoveSentence)])\n",
    "formatted_df['IMPRESSION'] = formatted_df['IMPRESSION'].apply(lambda x: [sentence for sentence in x if not any(word in sentence for word in toRemoveSentence)])\n",
    "\n",
    "finalDf = pd.DataFrame()\n",
    "finalDf['captions'] = formatted_df['FINDINGS'] + formatted_df['IMPRESSION']\n",
    "\n",
    "# remove ['as','above'],['status','quo']\n",
    "toRemoveSentence = ['above', 'quo']\n",
    "finalDf['captions'] = finalDf['captions'].apply(lambda x: [sentence for sentence in x if (not any(word in sentence for word in toRemoveSentence) and len(sentence) > 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split lists to row\n",
    "new = finalDf.explode('captions')\n",
    "newList = new['captions'].tolist()\n",
    "print(len(newList))\n",
    "# Convert each inner list to a tuple and add them to a set\n",
    "# print(type(newList))\n",
    "unique_ref = set()\n",
    "for x in newList:\n",
    "    if isinstance(x, list):\n",
    "        t = tuple(x)\n",
    "        unique_ref.add(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert from set of tuple to list of list\n",
    "unique_ref = [list(x) for x in unique_ref]\n",
    "print(len(unique_ref))\n",
    "print(unique_ref[7440])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in new.iterrows():\n",
    "    if index == 224:\n",
    "        print(\"captions: \",row['captions'])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(finalDf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in finalDf.iterrows():\n",
    "    if index == 223:\n",
    "        print(\"captions: \",row['captions'])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for index, row in formatted_df.iterrows():\n",
    "    if r'am' in (row['FINDINGS']) :\n",
    "        count+=1\n",
    "        print('index:', index)\n",
    "        print(\"FINDINGS: \",row['FINDINGS'])\n",
    "        print('-----------------------------------')\n",
    "        if r'am' in (row['IMPRESSION']):\n",
    "            count+=1\n",
    "            print(\"IMPRESSION: \",row['IMPRESSION'])\n",
    "            print('===================================')\n",
    "        \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for index, row in formatted_df.iterrows():\n",
    "    if r'since  ' in (row['FINDINGS']) :\n",
    "        count+=1\n",
    "        print('index:', index)\n",
    "        print(\"FINDINGS: \",row['FINDINGS'])\n",
    "        print('-----------------------------------')\n",
    "        if r'since  ' in (row['IMPRESSION']):\n",
    "            count+=1\n",
    "            print(\"IMPRESSION: \",row['IMPRESSION'])\n",
    "            print('===================================')\n",
    "        \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for index, row in formatted_df.iterrows():\n",
    "    if r'through  ' in (row['FINDINGS']) :\n",
    "        count+=1\n",
    "        print('index:', index)\n",
    "        print(\"FINDINGS: \",row['FINDINGS'])\n",
    "        print('-----------------------------------')\n",
    "        if r'through  ' in (row['IMPRESSION']):\n",
    "            count+=1\n",
    "            print(\"IMPRESSION: \",row['IMPRESSION'])\n",
    "            print('===================================')\n",
    "        \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for index, row in formatted_df.iterrows():\n",
    "    if r'at  ' in (row['FINDINGS']) :\n",
    "        count+=1\n",
    "        print('index:', index)\n",
    "        print(\"FINDINGS: \",row['FINDINGS'])\n",
    "        print('-----------------------------------')\n",
    "        if r'at  ' in (row['IMPRESSION']):\n",
    "            count+=1\n",
    "            print(\"IMPRESSION: \",row['IMPRESSION'])\n",
    "            print('===================================')\n",
    "        \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for index, row in formatted_df.iterrows():\n",
    "    if r'PICC' in (row['FINDINGS']) :\n",
    "        count+=1\n",
    "        print('index:', index)\n",
    "        print(\"FINDINGS: \",row['FINDINGS'])\n",
    "        print('-----------------------------------')\n",
    "        if r'PICC' in (row['IMPRESSION']):\n",
    "            count+=1\n",
    "            print(\"IMPRESSION: \",row['IMPRESSION'])\n",
    "            print('===================================')\n",
    "        \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for index, row in formatted_df.iterrows():\n",
    "    if r'from  ' in (row['FINDINGS']) :\n",
    "        count+=1\n",
    "        print('index:', index)\n",
    "        print(\"FINDINGS: \",row['FINDINGS'])\n",
    "        print('-----------------------------------')\n",
    "        if r'from  ' in (row['IMPRESSION']):\n",
    "            count+=1\n",
    "            print(\"IMPRESSION: \",row['IMPRESSION'])\n",
    "            print('===================================')\n",
    "        \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print sentences that has \"by\" in it from the dataframe formatted_df\n",
    "count = 0\n",
    "for index, row in formatted_df.iterrows():\n",
    "    if r'by  ' in (row['FINDINGS']) :\n",
    "        count+=1\n",
    "        print('index:', index)\n",
    "        print(\"FINDINGS: \",row['FINDINGS'])\n",
    "        print('-----------------------------------')\n",
    "        if r'by  ' in (row['IMPRESSION']):\n",
    "            count+=1\n",
    "            print(\"IMPRESSION: \",row['IMPRESSION'])\n",
    "            print('===================================')\n",
    "        \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in formatted_df.iterrows():\n",
    "    if index == 9:\n",
    "        print(\"FININDINS:\", row['FINDINGS'])\n",
    "        print(\"IMPRESSION:\", row['IMPRESSION'])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "x = \"1\"\n",
    "print(x.isdigit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "#bleu score for a single sentence\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "reference = [['this', 'is', 'a', 'test'], ['this', 'is', 'a', 'test']]\n",
    "candidate = ['this', 'are', 'test']\n",
    "\n",
    "score = sentence_bleu(reference, candidate)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
